{"cells":[{"cell_type":"code","source":["# https://dacon.io/en/codeshare/1803"],"metadata":{"id":"S-YBXlce5XvH","executionInfo":{"status":"ok","timestamp":1697718050081,"user_tz":-540,"elapsed":849,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"id":"S-YBXlce5XvH","execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34603,"status":"ok","timestamp":1697718085178,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"},"user_tz":-540},"id":"a1RK-GkfNjpT","outputId":"e0e50c96-dba0-46aa-860d-f2c20516695e"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'nsmc' already exists and is not an empty directory.\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.22.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n","Requirement already satisfied: mxnet in /usr/local/lib/python3.10/dist-packages (1.9.1)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.23.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2023.7.22)\n","Requirement already satisfied: gluonnlp==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.23.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-q3qommtj/kobert-tokenizer_f391321aa37449d7b4b9bb0a511e89d1\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-q3qommtj/kobert-tokenizer_f391321aa37449d7b4b9bb0a511e89d1\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["!git clone https://github.com/e9t/nsmc.git\n","!pip install tensorflow_addons\n","!pip install torch>=1.8.1\n","!pip install mxnet\n","!pip install gluonnlp==0.8.0\n","!pip install sentencepiece\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n","!pip install transformers"],"id":"a1RK-GkfNjpT"},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","TPU = False\n","if TPU:\n","  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","  tf.config.experimental_connect_to_cluster(resolver)\n","  tf.tpu.experimental.initialize_tpu_system(resolver)\n","else:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8GgxHk2bCZI","executionInfo":{"status":"ok","timestamp":1697718089414,"user_tz":-540,"elapsed":4244,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}},"outputId":"fc36626e-5b5e-49a6-9c98-d8dce92ff55b"},"id":"c8GgxHk2bCZI","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VYJ3D4yiNFrg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697718095139,"user_tz":-540,"elapsed":5728,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}},"outputId":"85dae8d2-932a-48e4-bd54-c5778e86311c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n","  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm, tqdm_notebook\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from kobert_tokenizer import KoBERTTokenizer\n","import gluonnlp as nlp\n","from transformers import pipeline, AutoTokenizer, BertTokenizer, BertTokenizerFast\n","from transformers import AutoModel, BertModel, TFBertModel, TFBertForSequenceClassification\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# 하이퍼파라미터\n","device = torch.device(\"cuda:0\")\n","max_len = 64\n","batch_size = 32\n","epoch = 100\n","learning_rate =  5e-5\n","warmup_ratio = 0.1\n","max_grad_norm = 1\n","log_interval = 200\n","modelsave_location = os.path.join(os.getcwd(), 'gdrive', 'MyDrive', 'Research',\n","                                  'Colab', 'Model', 'modeling_KoBERT_20231018.pt')\n","predfile_location = os.path.join(os.getcwd(), 'gdrive', 'MyDrive', 'Research',\n","                                  'Colab', 'Data', 'df_news.csv')\n","\n","class BERTSentenceTransform:\n","    r\"\"\"BERT style data transformation.\n","\n","    Parameters\n","    ----------\n","    tokenizer : BERTTokenizer.\n","        Tokenizer for the sentences.\n","    max_seq_length : int.\n","        Maximum sequence length of the sentences.\n","    pad : bool, default True\n","        Whether to pad the sentences to maximum length.\n","    pair : bool, default True\n","        Whether to transform sentences or sentence pairs.\n","    \"\"\"\n","\n","    def __init__(self, tokenizer, max_seq_length,vocab, pad=True, pair=True):\n","        self._tokenizer = tokenizer\n","        self._max_seq_length = max_seq_length\n","        self._pad = pad\n","        self._pair = pair\n","        self._vocab = vocab\n","\n","    def __call__(self, line):\n","        \"\"\"Perform transformation for sequence pairs or single sequences.\n","\n","        The transformation is processed in the following steps:\n","        - tokenize the input sequences\n","        - insert [CLS], [SEP] as necessary\n","        - generate type ids to indicate whether a token belongs to the first\n","        sequence or the second sequence.\n","        - generate valid length\n","\n","        For sequence pairs, the input is a tuple of 2 strings:\n","        text_a, text_b.\n","\n","        Inputs:\n","            text_a: 'is this jacksonville ?'\n","            text_b: 'no it is not'\n","        Tokenization:\n","            text_a: 'is this jack ##son ##ville ?'\n","            text_b: 'no it is not .'\n","        Processed:\n","            tokens: '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n","            type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n","            valid_length: 14\n","\n","        For single sequences, the input is a tuple of single string:\n","        text_a.\n","\n","        Inputs:\n","            text_a: 'the dog is hairy .'\n","        Tokenization:\n","            text_a: 'the dog is hairy .'\n","        Processed:\n","            text_a: '[CLS] the dog is hairy . [SEP]'\n","            type_ids: 0     0   0   0  0     0 0\n","            valid_length: 7\n","\n","        Parameters\n","        ----------\n","        line: tuple of str\n","            Input strings. For sequence pairs, the input is a tuple of 2 strings:\n","            (text_a, text_b). For single sequences, the input is a tuple of single\n","            string: (text_a,).\n","\n","        Returns\n","        -------\n","        np.array: input token ids in 'int32', shape (batch_size, seq_length)\n","        np.array: valid length in 'int32', shape (batch_size,)\n","        np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n","\n","        \"\"\"\n","\n","        # convert to unicode\n","        text_a = line[0]\n","        if self._pair:\n","            assert len(line) == 2\n","            text_b = line[1]\n","\n","        tokens_a = self._tokenizer.tokenize(text_a)\n","        tokens_b = None\n","\n","        if self._pair:\n","            tokens_b = self._tokenizer(text_b)\n","\n","        if tokens_b:\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\n","            # length is less than the specified length.\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","            self._truncate_seq_pair(tokens_a, tokens_b,\n","                                    self._max_seq_length - 3)\n","        else:\n","            # Account for [CLS] and [SEP] with \"- 2\"\n","            if len(tokens_a) > self._max_seq_length - 2:\n","                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n","\n","        # The embedding vectors for `type=0` and `type=1` were learned during\n","        # pre-training and are added to the wordpiece embedding vector\n","        # (and position vector). This is not *strictly* necessary since\n","        # the [SEP] token unambiguously separates the sequences, but it makes\n","        # it easier for the model to learn the concept of sequences.\n","\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\n","        # used as as the \"sentence vector\". Note that this only makes sense because\n","        # the entire model is fine-tuned.\n","        #vocab = self._tokenizer.vocab\n","        vocab = self._vocab\n","        tokens = []\n","        tokens.append(vocab.cls_token)\n","        tokens.extend(tokens_a)\n","        tokens.append(vocab.sep_token)\n","        segment_ids = [0] * len(tokens)\n","\n","        if tokens_b:\n","            tokens.extend(tokens_b)\n","            tokens.append(vocab.sep_token)\n","            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n","\n","        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # The valid length of sentences. Only real  tokens are attended to.\n","        valid_length = len(input_ids)\n","\n","        if self._pad:\n","            # Zero-pad up to the sequence length.\n","            padding_length = self._max_seq_length - valid_length\n","            # use padding tokens for the rest\n","            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n","            segment_ids.extend([0] * padding_length)\n","\n","        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n","            np.array(segment_ids, dtype='int32')\n","\n","class BERTDataset():\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n","                 pad, pair):\n","        transform = BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n","        #transform = nlp.data.BERTSentenceTransform(\n","        #    tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=5,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","\n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","\n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"id":"VYJ3D4yiNFrg"},{"cell_type":"code","source":["# # 데이터처리\n","# train = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\n","# train = train.dropna().sample(5000).reset_index().iloc[:,1:].iloc[:,1:].values.tolist()\n","# test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")\n","# test = test.dropna().sample(5000).reset_index().iloc[:,1:].iloc[:,1:].values.tolist()\n","\n","# tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","# vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n","# bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n","\n","# data_train = BERTDataset(train, 0, 1, tokenizer, vocab, max_len, True, False)\n","# data_test = BERTDataset(test, 0, 1, tokenizer, vocab, max_len, True, False)\n","# train_dataloader = DataLoader(data_train, batch_size=batch_size, num_workers=2)\n","# test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=2)\n","\n","# # 모델링세팅\n","# model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","# loss_fn = nn.CrossEntropyLoss()\n","# no_decay = ['bias', 'LayerNorm.weight']\n","# optimizer_grouped_parameters = [\n","#     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","#     {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","# ]\n","# optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","\n","# t_total = len(train_dataloader) * epoch\n","# warmup_step = int(t_total * warmup_ratio)\n","# scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","# def calc_accuracy(X,Y):\n","#     max_vals, max_indices = torch.max(X, 1)\n","#     train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","#     return train_acc\n","\n","# # 학습\n","# train_history = []\n","# test_history = []\n","# loss_history = []\n","\n","# for e in range(epoch):\n","#     train_acc = 0.0\n","#     test_acc = 0.0\n","#     model.train()\n","#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","#         optimizer.zero_grad()\n","#         token_ids = token_ids.long().to(device)\n","#         segment_ids = segment_ids.long().to(device)\n","#         valid_length= valid_length\n","#         label = label.long().to(device)\n","#         out = model(token_ids, valid_length, segment_ids)\n","#         # print(label.shape, out.shape)\n","#         loss = loss_fn(out, label)\n","#         loss.backward()\n","#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","#         optimizer.step()\n","#         scheduler.step()  # Update learning rate schedule\n","#         train_acc += calc_accuracy(out, label)\n","#         if batch_id % log_interval == 0:\n","#             print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","#             train_history.append(train_acc / (batch_id+1))\n","#             loss_history.append(loss.data.cpu().numpy())\n","#     print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","#     # train_history.append(train_acc / (batch_id+1))\n","#     model.eval() # 모델을 평가 모드로 설정\n","#     for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","#         token_ids = token_ids.long().to(device)\n","#         segment_ids = segment_ids.long().to(device)\n","#         valid_length= valid_length\n","#         label = label.long().to(device)\n","#         out = model(token_ids, valid_length, segment_ids) # 모델에 입력 데이터 전달하여 출력 얻기\n","#         test_acc += calc_accuracy(out, label) # 정확도 계산하여 누적\n","#     print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n","#     test_history.append(test_acc / (batch_id+1)) # 테스트 정확도의 추이를 기록하고 후에 시각화하거나 분석하는 데 사용\n","\n","# # 모델저장\n","# torch.save(model.state_dict(), modelsave_location)\n","\n","# # 시각화\n","# epochs = range(1, epoch + 1)\n","# display(train_history, test_history)\n","# ## training and test accuracy\n","# plt.figure(figsize=(12, 6))\n","# plt.subplot(1, 2, 1)\n","# plt.plot(epochs, train_history, 'bo-', label='Training Accuracy')\n","# plt.plot(epochs, test_history, 'ro-', label='Test Accuracy')\n","# plt.title('Training and Test Accuracy')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Accuracy')\n","# plt.legend()\n","# ## training loss\n","# plt.subplot(1, 2, 2)\n","# plt.plot(epochs, loss_history, 'go-')\n","# plt.title('Loss-Epochs')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Loss')\n","# plt.tight_layout()\n","# plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":884,"referenced_widgets":["14f5d8ba9a984f4ab23e44f5a4a10db2","95717f0679974283b3d61026635a4190","910d978b660049b186a6eec101d1bb99","6360dad852b1432eac1527c8ae3a8cf5","8c77d07d3d844cf79fb06b4ea6d21437","abfdfaea7dfa4909922597414501f9c5","b39f7b5aef7f4239b60c72d1a71ed087","dbd97f1f2f2a4ac2944371a8faa34c11","55dbef8017cb46999d8021f9a4a0829f","9a4b1b254b8749a1ad2b21cf0b3ceb8b","8484e5b2d74b442289e9ef37b0dd0b8d","2feb2521942f4bc3ae3115c5d3b31f47","36ebb31b23de4fa6a9244c64a40719fb","1b27168e48c145eeaa1e8996d6289a9f","af363cbee8194b32876df65b31b45003","aa91f405e7034097b619a639ec536ad8","7d03594dae4c4491af0d0643511ca827","6f43451dccc746558ba061b30da1e225","d7aa96f5a96b4d6da56ece0c78d4cf84","07bf17afe39d49fc8ff7c9a3583e6e92","0a4459ea0adb40a6934bd6f632939537","1ac29366255840fe9e637c62eb1dc729","28b6139898ee43738dc3bf2eaa395459","b561f0be954f4f1cb0abb74207627934","b30dad02de404898822cb2e449c486cd","9def2bb088b548d2a8e4905e0b281d69","b19041fad4da491bb298289251668402","7d7a18be87124477bb74fe71f76a1eb7","67400d175b28429d94403e66a26691b7","824018022f044e39953e52ca69f05209","fbc6a67a442e4f6aa741a1b476928309","2635ae3209cf4b36a4b906a317e86b64","7e22a71369214eb09754895bff71093d"]},"id":"ZxlrtEzrMRPO","outputId":"243e14b1-1e54-4ec9-cf85-e01e4305fbbd","executionInfo":{"status":"error","timestamp":1697718221785,"user_tz":-540,"elapsed":126648,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"id":"ZxlrtEzrMRPO","execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","<ipython-input-5-125f134a7c39>:44: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/157 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14f5d8ba9a984f4ab23e44f5a4a10db2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 1 batch id 1 loss 1.6132630109786987 train acc 0.25\n","epoch 1 train acc 0.464171974522293\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-125f134a7c39>:65: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/157 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2feb2521942f4bc3ae3115c5d3b31f47"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 1 test acc 0.6194267515923567\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-125f134a7c39>:44: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/157 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28b6139898ee43738dc3bf2eaa395459"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch 2 batch id 1 loss 0.901033878326416 train acc 0.59375\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-125f134a7c39>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update learning rate schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 모델 및 예측데이터 로딩\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n","bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n","model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","model.load_state_dict(torch.load(modelsave_location))\n","df_news = pd.read_csv(predfile_location)\n","## 예측함수\n","def predict_sentiment(sentence):\n","    data = [sentence, '0']\n","    dataset = [data]\n","    test_data = BERTDataset(dataset, 0, 1, tokenizer, vocab, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=5)\n","\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length = valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        predicted_index = out.argmax() + 1\n","\n","    return predicted_index.item()\n","## 예측\n","tqdm.pandas()\n","# df_news_sentiment = df_news['제목'][:100000].progress_apply(predict_sentiment)\n","# predsave_location = os.path.join(os.getcwd(), 'gdrive', 'MyDrive', 'Research',\n","#                                   'Colab', 'Data', 'df_news_sentiment1.csv')\n","# df_news_sentiment.to_csv(predsave_location)\n","for i in range(200000, 300000, 10000):\n","    df_news_sentiment = df_news['제목'][i:i+10000].progress_apply(predict_sentiment)\n","    predsave_location = os.path.join(os.getcwd(), 'gdrive', 'MyDrive', 'Research',\n","                                     'Colab', 'Data', 'df_news_sentiment'+str(i)+'.csv')\n","    df_news_sentiment.to_csv(predsave_location)"],"metadata":{"id":"AZRB_Jpyax-K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2bdefd06-e049-4772-f8b2-b81d9ae66468"},"id":"AZRB_Jpyax-K","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n","100%|██████████| 10000/10000 [51:00<00:00,  3.27it/s]\n"," 68%|██████▊   | 6804/10000 [44:57<24:31,  2.17it/s]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uuc69lF3e4q7","executionInfo":{"status":"aborted","timestamp":1697718221785,"user_tz":-540,"elapsed":2,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"id":"uuc69lF3e4q7","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"06bKk_MJe4t3","executionInfo":{"status":"aborted","timestamp":1697718221785,"user_tz":-540,"elapsed":2,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"id":"06bKk_MJe4t3","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YdyvMEeMKHTs","executionInfo":{"status":"aborted","timestamp":1697718221785,"user_tz":-540,"elapsed":2,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"id":"YdyvMEeMKHTs","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20421f35","executionInfo":{"status":"aborted","timestamp":1697718221786,"user_tz":-540,"elapsed":3,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"outputs":[],"source":["# # !git clone https://github.com/e9t/nsmc.git\n","# train = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\n","# train = train.dropna().sample(5000).reset_index().iloc[:,1:]\n","# test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")\n","# test = test.dropna().sample(5000).reset_index().iloc[:,1:]\n","\n","# data_train = BERTDataset(train, 0, 1, tokenizer, vocab, max_len, True, False)\n","# data_test = BERTDataset(test, 0, 1, tokenizer, vocab, max_len, True, False)\n","\n","\n","# def preprocessing_sentence_to_BERTinput(df, tokenizer, colname_data, colname_target=None, seq_len=128,\n","#                                         return_type='tensor'):\n","#     tokens, masks, segments, targets = [], [], [], []\n","#     for i in tqdm(range(len(df))):\n","#         # 변환\n","#         token = tokenizer.encode_plus(df[colname_data][i], max_length=seq_len,\n","#                                       pad_to_max_length=True, truncation=True,\n","#                                       return_attention_mask=True,\n","#                                       add_special_tokens=True)\n","\n","#         # 정리\n","#         tokens.append(token['input_ids'])\n","#         masks.append(token['attention_mask'])\n","#         segments.append(token['token_type_ids'])\n","#         if colname_target != None:\n","#             targets.append(df[colname_target][i])\n","\n","#     # array 변환\n","#     tokens = np.array(tokens)\n","#     masks = np.array(masks)\n","#     segments = np.array(segments)\n","#     if colname_target != None:\n","#         targets = np.array(targets)\n","\n","#     # tensor 변환\n","#     if return_type == 'tensor':\n","#         tokens = tf.convert_to_tensor(tokens, dtype=tf.int32)\n","#         masks = tf.convert_to_tensor(masks, dtype=tf.int32)\n","#         segments = tf.convert_to_tensor(segments, dtype=tf.int32)\n","\n","#     return [tokens, masks, segments], targets\n","\n","# import tensorflow_addons as tfa\n","# from transformers import pipeline, AutoTokenizer, BertTokenizer, BertTokenizerFast\n","# from transformers import AutoModel, AutoModelForTokenClassification, TFBertModel, TFBertForSequenceClassification\n","\n","# MODEL_NAME = 'monologg/kobert'    # 'bert-base-multilingual-cased', 'klue/roberta-base'\n","# # OPTIMIZER = tfa.optimizers.RectifiedAdam(lr=1.0e-5, weight_decay=0.0025, warmup_proportion=0.05)\n","# OPTIMIZER = tf.keras.optimizers.Adam(lr=1.0e-5)\n","# NUM_LABELS = 2\n","# SEQ_LEN = 64\n","\n","# tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n","# X_train, Y_train = preprocessing_sentence_to_BERTinput(train, tokenizer=tokenizer,\n","#                                                        colname_target='label', colname_data='document', seq_len=SEQ_LEN)\n","# X_test, Y_test = preprocessing_sentence_to_BERTinput(test, tokenizer=tokenizer,\n","#                                                        colname_target='label', colname_data='document', seq_len=SEQ_LEN)\n","\n","# def modeling_BERTsentiment(model_name, optimizer, num_labels=2, seq_len=128):\n","#     # 모델 로딩\n","#     model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","#     loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","#     metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","#     model.compile(optimizer=optimizer, loss=loss, metrics=metric)\n","\n","#     return model\n","\n","# # def modeling_BERTsentiment(model_name, optimizer, num_labels=2, seq_len=128):\n","# #     # 모델 로딩\n","# #     model = TFBertModel.from_pretrained(model_name, num_labels=num_labels, output_hidden_states=True)\n","# #     outputs = model([tokens, masks, segments])[1]\n","\n","# #     # 모델 구성\n","# #     layer = tf.keras.layers.Dense(1, activation='sigmoid',\n","# #                                   kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(outputs)\n","# #     model_sentiment = tf.keras.Model([tokens, masks, segments], layer)\n","# #     model_sentiment.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n","\n","# #     return model_sentiment\n","\n","\n","# model = modeling_BERTsentiment(model_name=MODEL_NAME, optimizer=OPTIMIZER, num_labels=NUM_LABELS, seq_len=SEQ_LEN)\n","# model.fit(X_train, Y_train, epochs=10, shuffle=True, batch_size=100, validation_data=(X_test, Y_test))\n"],"id":"20421f35"},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCMFpXiYO5zC","executionInfo":{"status":"aborted","timestamp":1697718221786,"user_tz":-540,"elapsed":3,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"outputs":[],"source":[],"id":"mCMFpXiYO5zC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJFTUj4iO6xQ","executionInfo":{"status":"aborted","timestamp":1697718221786,"user_tz":-540,"elapsed":3,"user":{"displayName":"Kyungwon Kim","userId":"12494571024836189016"}}},"outputs":[],"source":[],"id":"HJFTUj4iO6xQ"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"14f5d8ba9a984f4ab23e44f5a4a10db2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95717f0679974283b3d61026635a4190","IPY_MODEL_910d978b660049b186a6eec101d1bb99","IPY_MODEL_6360dad852b1432eac1527c8ae3a8cf5"],"layout":"IPY_MODEL_8c77d07d3d844cf79fb06b4ea6d21437"}},"95717f0679974283b3d61026635a4190":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abfdfaea7dfa4909922597414501f9c5","placeholder":"​","style":"IPY_MODEL_b39f7b5aef7f4239b60c72d1a71ed087","value":"100%"}},"910d978b660049b186a6eec101d1bb99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd97f1f2f2a4ac2944371a8faa34c11","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55dbef8017cb46999d8021f9a4a0829f","value":157}},"6360dad852b1432eac1527c8ae3a8cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a4b1b254b8749a1ad2b21cf0b3ceb8b","placeholder":"​","style":"IPY_MODEL_8484e5b2d74b442289e9ef37b0dd0b8d","value":" 157/157 [00:57&lt;00:00,  3.55it/s]"}},"8c77d07d3d844cf79fb06b4ea6d21437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abfdfaea7dfa4909922597414501f9c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b39f7b5aef7f4239b60c72d1a71ed087":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbd97f1f2f2a4ac2944371a8faa34c11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55dbef8017cb46999d8021f9a4a0829f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a4b1b254b8749a1ad2b21cf0b3ceb8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8484e5b2d74b442289e9ef37b0dd0b8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2feb2521942f4bc3ae3115c5d3b31f47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36ebb31b23de4fa6a9244c64a40719fb","IPY_MODEL_1b27168e48c145eeaa1e8996d6289a9f","IPY_MODEL_af363cbee8194b32876df65b31b45003"],"layout":"IPY_MODEL_aa91f405e7034097b619a639ec536ad8"}},"36ebb31b23de4fa6a9244c64a40719fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d03594dae4c4491af0d0643511ca827","placeholder":"​","style":"IPY_MODEL_6f43451dccc746558ba061b30da1e225","value":"100%"}},"1b27168e48c145eeaa1e8996d6289a9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7aa96f5a96b4d6da56ece0c78d4cf84","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07bf17afe39d49fc8ff7c9a3583e6e92","value":157}},"af363cbee8194b32876df65b31b45003":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a4459ea0adb40a6934bd6f632939537","placeholder":"​","style":"IPY_MODEL_1ac29366255840fe9e637c62eb1dc729","value":" 157/157 [00:18&lt;00:00,  8.51it/s]"}},"aa91f405e7034097b619a639ec536ad8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d03594dae4c4491af0d0643511ca827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f43451dccc746558ba061b30da1e225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7aa96f5a96b4d6da56ece0c78d4cf84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07bf17afe39d49fc8ff7c9a3583e6e92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a4459ea0adb40a6934bd6f632939537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ac29366255840fe9e637c62eb1dc729":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28b6139898ee43738dc3bf2eaa395459":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b561f0be954f4f1cb0abb74207627934","IPY_MODEL_b30dad02de404898822cb2e449c486cd","IPY_MODEL_9def2bb088b548d2a8e4905e0b281d69"],"layout":"IPY_MODEL_b19041fad4da491bb298289251668402"}},"b561f0be954f4f1cb0abb74207627934":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7a18be87124477bb74fe71f76a1eb7","placeholder":"​","style":"IPY_MODEL_67400d175b28429d94403e66a26691b7","value":" 85%"}},"b30dad02de404898822cb2e449c486cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_824018022f044e39953e52ca69f05209","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbc6a67a442e4f6aa741a1b476928309","value":133}},"9def2bb088b548d2a8e4905e0b281d69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2635ae3209cf4b36a4b906a317e86b64","placeholder":"​","style":"IPY_MODEL_7e22a71369214eb09754895bff71093d","value":" 133/157 [00:46&lt;00:08,  2.87it/s]"}},"b19041fad4da491bb298289251668402":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d7a18be87124477bb74fe71f76a1eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67400d175b28429d94403e66a26691b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"824018022f044e39953e52ca69f05209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbc6a67a442e4f6aa741a1b476928309":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2635ae3209cf4b36a4b906a317e86b64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e22a71369214eb09754895bff71093d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}