{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f9246d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T03:26:27.614051Z",
     "start_time": "2023-10-14T03:26:26.908732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore the warnings\n",
    "import warnings\n",
    "# warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# System related and data input controls\n",
    "import os\n",
    "\n",
    "# Auto reload of library\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data_crawling_navernews import *\n",
    "from data_crawling_naverblogs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c56736",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-14T03:26:27.623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고령화\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "KEYWORD_LOCATION = os.path.join(os.getcwd(), '[Document]', 'Target_Keywords.xlsx')\n",
    "QUERY_LIST = list(pd.read_excel(KEYWORD_LOCATION)['실제검색어'])[:2]\n",
    "# QUERY_LIST = ['노인+부양']\n",
    "START = \"20230101\"\n",
    "END = \"20230931\"\n",
    "SORT = 0\n",
    "MAXPAGE = 100\n",
    "MAXPAGE_COUNT = False\n",
    "SAVE = True\n",
    "# data loading\n",
    "for QUERY in QUERY_LIST:\n",
    "    print(QUERY)\n",
    "    df = get_data_from_navernews(search_query=QUERY, start=START, end=END, sort=SORT, \n",
    "                                 maxpage=MAXPAGE, maxpage_count=MAXPAGE_COUNT, save_local=SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bb4c76",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1de577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:35:21.030819Z",
     "start_time": "2023-10-14T00:35:11.209777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA is in the system path?:  False\n",
      "JAVA is in the system path?:  Adding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ignore the warnings\n",
    "import warnings\n",
    "# warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# System related and data input controls\n",
    "import os\n",
    "\n",
    "# Python path\n",
    "import sys\n",
    "base_folder = 'DataScience'\n",
    "location_base = os.path.join(os.getcwd().split(base_folder)[0], base_folder)\n",
    "location_module = [os.path.join(location_base, 'Module')] \n",
    "for each in location_module:\n",
    "    if each not in sys.path:\n",
    "        sys.path.append(each)\n",
    "\n",
    "# Auto reload of library\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from import_KK import *\n",
    "DeviceStrategy_CPU()\n",
    "from preprocessing_KK import *\n",
    "from preprocessing_text_KK import * ##\n",
    "from visualization_KK import * ##\n",
    "from algorithm_KK import *\n",
    "from evaluation_KK import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a5fb6",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806a928d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:35:21.180998Z",
     "start_time": "2023-10-14T00:35:21.032173Z"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "FOLDER_LOCATION = os.path.join(os.getcwd(), 'Data', '빅카인즈')\n",
    "FOLDER_NAME = True\n",
    "CATEGORY = ['경제', '사회', '문화', '국제']\n",
    "IMAGE_LOCATION = os.path.join('.', 'Data', 'baby-icon_ver1.png')\n",
    "COLNAME_CATEGORY = '일자'\n",
    "COLNAME_MINING = '제목'\n",
    "CONSERVATIVE = ['동아일보', '중앙일보', '조선일보', '매일경제', '한국경제']\n",
    "PROGRESSIVE = ['한겨례', '경향신문', '머니투데이']\n",
    "################\n",
    "test_criteria = '2023-01-01'\n",
    "SEQUENCE = 5\n",
    "Y_SCALING = True\n",
    "MOVING_TYPE = 'sliding'    # 'sliding', 'expanding'\n",
    "TRAIN_WINDOW = 100\n",
    "FORECASTING_PERIOD = 4+24\n",
    "################\n",
    "# metrics.SCORERS.keys(): 'neg_mean_squared_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'\n",
    "LOSS_ML = 'neg_mean_squared_error' \n",
    "PARAMS_BAG = None\n",
    "# PARAMS_BAG = {'n_estimators': [30, 50, 90],     \n",
    "#           'max_depth': [20, 30, 40, 50],  \n",
    "#           'max_leaf_nodes': [5, 10, 15]}\n",
    "PARAMS_BOOST = None\n",
    "# PARAMS_BOOST = {'n_estimators': [30, 50, 90],    \n",
    "#           'max_depth': [20, 30, 40, 50],   \n",
    "#           'num_leaves': [5, 10, 15],\n",
    "#           'min_child_weight': [3, 5, 7],\n",
    "#           'learning_rate': [0.1, 0.01],\n",
    "#           'force_col_wise': [False], 'force_row_wise': [True]}\n",
    "CV_SPLITS = 5\n",
    "################\n",
    "KERNEL_SIZE = 2\n",
    "STRIDE = 1\n",
    "POOL_SIZE = 1\n",
    "POOL_STRIDE = 1\n",
    "HIDDEN_ACTIVATION = 'relu'\n",
    "OUTPUT_ACTIVATION = 'linear'\n",
    "REGULARIZER = None\n",
    "DROPOUT_RATIO = 0.2\n",
    "MODEL_SUMMARY = False\n",
    "LOSS = 'mse'\n",
    "LEARNING_RATE = 0.01\n",
    "OPTIMIZER = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "METRICS = ['mse']\n",
    "VALIDATION_SPLIT = 0.2\n",
    "VALIDATION_DATA = None\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "VERBOSE = 0\n",
    "################\n",
    "EARLYSTOP_PATIENT = EPOCHS*0.4\n",
    "MONITOR = 'val_loss'\n",
    "LEARNING_PLOT = False\n",
    "PLOT_TITLE = \"How People's Interest Changes Over Time\"\n",
    "PLOT_XLABEL = 'Time'\n",
    "PLOT_YLABEL = 'Interest Forecasting'\n",
    "################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471c419",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7cd01",
   "metadata": {},
   "source": [
    "## Google Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e01525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:35:21.544210Z",
     "start_time": "2023-10-14T00:35:21.180998Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터로딩\n",
    "file_location = os.path.join(os.getcwd(), 'Data', 'ageism_survey_KK.xlsx')\n",
    "df_gt = pd.read_excel(file_location, sheet_name='GT_Trend', index_col='Time')\n",
    "df_gt_global = df_gt[['Ageism']].copy()\n",
    "df_gt_local = df_gt[['고령화']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb30016",
   "metadata": {},
   "source": [
    "## BigKinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf1a57b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:40:30.374176Z",
     "start_time": "2023-10-14T00:35:21.545208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from 39 folders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.05s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:20<00:00,  1.89s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.20s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.61s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.47s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.08s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:28<00:00,  2.56s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.75s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.49s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.15s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.77s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사회>의료_건강', '문화>방송_연예', '사회>노동_복지', '경제>금융_재테크', '경제>경제일반', '국제>중국', '국제>유럽_EU', '문화>출판', '경제>취업_창업', '경제>부동산', '국제>일본', '경제>산업_기업', '경제>유통', '사회>교육_시험', '사회>여성', '국제>미국_북미', '경제>증권_증시', '문화>미술_건축', '문화>음악', '문화>문화일반', '경제>자동차', '문화>학술_문화재', '국제>중동_아프리카', '사회>사회일반', '문화>생활', '문화>종교', '경제>국제경제', '사회>미디어', '경제>무역', '국제>아시아', '국제>중남미', '경제>서비스_쇼핑', '문화>전시_공연', '경제>반도체', '문화>요리_여행', '문화>영화', '사회>사건_사고', '국제>국제일반', '경제>자원', '사회>장애인', '국제>러시아', '경제>외환', '사회>환경', '사회>날씨']\n"
     ]
    }
   ],
   "source": [
    "# ### 하위의 모든 데이터 결합하여 출력\n",
    "# def get_data_from_path(folder_location, folder_name=False, concat_axis='row'):\n",
    "#     # path_folder 하위의 모든 폴더위치와 내부 file 출력\n",
    "#     df = pd.DataFrame()\n",
    "#     print('Getting data from', len(os.listdir(folder_location)), 'folders...')\n",
    "#     for (path, dir, files) in os.walk(folder_location):\n",
    "#         for file in tqdm(files):\n",
    "#             path_file = os.path.join(path, file)\n",
    "\n",
    "#             ## 데이터 로딩\n",
    "#             if path_file.split('.')[1] == 'xlsx':\n",
    "#                 df_sub = pd.read_excel(path_file)\n",
    "#             elif path_file.split('.')[1] == 'csv':\n",
    "#                 df_sub = pd.read_csv(path_file)\n",
    "                \n",
    "#             ## 키워드 태깅 여부\n",
    "#             if folder_name:\n",
    "#                 df_sub['Folder_Name'] = os.path.basename(path)\n",
    "            \n",
    "#             ## 정리\n",
    "#             if concat_axis == 'col':\n",
    "#                 df = pd.concat([df, df_sub], axis=1)\n",
    "#             elif concat_axis == 'row':\n",
    "#                 df = pd.concat([df, df_sub], axis=0)\n",
    "                \n",
    "#     return df\n",
    "\n",
    "# # 데이터로딩\n",
    "# df_news = get_data_from_path(FOLDER_LOCATION, folder_name=FOLDER_NAME)\n",
    "# ## 중복 처리\n",
    "# df_news.drop_duplicates(subset=['뉴스 식별자', '언론사', '제목'], inplace=True, ignore_index=True)\n",
    "# ## 날짜 인식\n",
    "# df_news['일자'] = pd.to_datetime(df_news['일자'].astype(str))\n",
    "# ## 월별 트랜드용 데이터분리\n",
    "# df_news_rising = df_news[['Folder_Name', '일자', '제목']].copy()\n",
    "# df_news_rising['일자'] = pd.to_datetime(df_news_rising['일자'].dt.strftime('%Y-%m'))\n",
    "# df_news_rising = df_news_rising.groupby(['Folder_Name', '일자'])['제목'].count().unstack(level=0).fillna(0)\n",
    "# ## 연도만 남기기\n",
    "# df_news['일자'] = df_news['일자'].dt.year\n",
    "# ## 카테고리 필터\n",
    "# category_filter = [each for each in df_news['통합 분류1'].unique() if each.split('>')[0] in CATEGORY]\n",
    "# print(category_filter)\n",
    "# df_news = df_news[df_news['통합 분류1'].apply(lambda x: x in category_filter)].reset_index().iloc[:,1:]\n",
    "# ## 전처리\n",
    "# df_news['제목'] = df_news['제목'].apply(lambda x: text_preprocessor(x, del_number=False, del_bracket_content=False))\n",
    "# ## 결측치 및 빈문자 제거\n",
    "# df_news = df_news[~df_news['제목'].isnull()].reset_index().iloc[:,1:].copy()\n",
    "# df_news = df_news[df_news['제목'].str.len() != 0].reset_index().iloc[:,1:]\n",
    "# ## 언론사 분리\n",
    "# df_newsc = df_news[df_news['언론사'].isin(CONSERVATIVE)].reset_index()\n",
    "# df_newsp = df_news[df_news['언론사'].isin(PROGRESSIVE)].reset_index()\n",
    "# ## 날짜 변환 데이터\n",
    "# df_news_era, df_newsc_era, df_newsp_era = df_news.copy(), df_newsc.copy(), df_newsp.copy()\n",
    "# df_news_era['일자'] = df_news_era['일자'].apply(lambda x: '2013 ~ 2017' if x in [2013, 2014, 2015, 2016, 2017] \n",
    "#                                                                          else '2018 ~ 2023')\n",
    "# df_newsc_era['일자'] = df_newsc_era['일자'].apply(lambda x: '2013 ~ 2017' if x in [2013, 2014, 2015, 2016, 2017] \n",
    "#                                                                          else '2018 ~ 2023')\n",
    "# df_newsp_era['일자'] = df_newsp_era['일자'].apply(lambda x: '2013 ~ 2017' if x in [2013, 2014, 2015, 2016, 2017] \n",
    "#                                                                          else '2018 ~ 2023')\n",
    "# ## 저장\n",
    "# df_news_rising.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_news_rising.csv'), index=False, encoding='utf-8-sig')\n",
    "# df_news.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_news.csv'), index=False, encoding='utf-8-sig')\n",
    "# df_newsc.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsc.csv'), index=False, encoding='utf-8-sig')\n",
    "# df_newsp.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsp.csv'), index=False, encoding='utf-8-sig')\n",
    "# df_news_era.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_news_era.csv'), index=False, encoding='utf-8-sig')\n",
    "# df_newsc_era.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsc_era.csv'), index=False, encoding='utf-8-sig')\n",
    "# df_newsp_era.to_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsp_era.csv'), index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049b5828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:41:08.723361Z",
     "start_time": "2023-10-14T00:40:30.375174Z"
    }
   },
   "outputs": [],
   "source": [
    "## 불러오기\n",
    "df_news_rising = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_news_rising.csv'))\n",
    "df_news = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_news.csv'))\n",
    "df_newsc = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsc.csv'))\n",
    "df_newsp = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsp.csv'))\n",
    "df_news_era = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_news_era.csv'))\n",
    "df_newsc_era = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsc_era.csv'))\n",
    "df_newsp_era = pd.read_csv(os.path.join(r'C:\\Users\\KK\\Desktop', 'df_newsp_era.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8fd42",
   "metadata": {},
   "source": [
    "## Word Frequency\n",
    "\n",
    "- **데이터:** 구글 뉴스 + 네이버 뉴스\n",
    "- **카테고리:** 경세 + 사회 + 문화 + 국제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03638b4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T00:41:08.902038Z",
     "start_time": "2023-10-14T00:41:08.724366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 언론사: ['아주경제' '동아일보' '세계일보' '머니투데이' '중앙일보' '서울경제' '헤럴드경제' '문화일보' '국민일보' '서울신문'\n",
      " '디지털타임스' '한국경제' '아시아경제' '매일경제' '내일신문' 'SBS' '파이낸셜뉴스' '경향신문' '전자신문' '한겨레'\n",
      " 'YTN' '한국일보' 'MBC' 'OBS' 'KBS' '조선일보']\n",
      "\n",
      "보수 언론사: ['동아일보' '중앙일보' '한국경제' '매일경제' '조선일보']\n",
      "\n",
      "진보 언론하: ['머니투데이' '경향신문']\n"
     ]
    }
   ],
   "source": [
    "print('전체 언론사:', df_news['언론사'].unique())\n",
    "print('\\n보수 언론사:', df_newsc['언론사'].unique())\n",
    "print('\\n진보 언론하:', df_newsp['언론사'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0904f61e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:32:00.125963Z",
     "start_time": "2023-10-14T00:41:08.903038Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 6.059 Gbory 6.017 Gb\n",
      "all cohesion probabilities was computed. # words = 25255\n",
      "all branching entropies was computed # words = 46474\n",
      "all accessor variety was computed # words = 46474\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 30644\n",
      "_noun_scores_ 6365\n",
      "after postprocessing 4365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▌                                                                           | 1/11 [01:32<15:23, 92.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 4.963 Gbory 4.842 Gb\n",
      "all cohesion probabilities was computed. # words = 28782\n",
      "all branching entropies was computed # words = 49656\n",
      "all accessor variety was computed # words = 49656\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 34088\n",
      "_noun_scores_ 7238\n",
      "after postprocessing 4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                   | 2/11 [03:38<16:49, 112.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.775 Gbory 2.642 Gb\n",
      "all cohesion probabilities was computed. # words = 36363\n",
      "all branching entropies was computed # words = 68449\n",
      "all accessor variety was computed # words = 68449\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 42969\n",
      "_noun_scores_ 8749\n",
      "after postprocessing 6027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▎                                                           | 3/11 [06:45<19:31, 146.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 4.387 Gbory 4.268 Gb\n",
      "all cohesion probabilities was computed. # words = 30448\n",
      "all branching entropies was computed # words = 45627\n",
      "all accessor variety was computed # words = 45627\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 36022\n",
      "_noun_scores_ 7568\n",
      "after postprocessing 5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▊                                                    | 4/11 [09:04<16:44, 143.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 5.336 Gbory 5.217 Gb\n",
      "all cohesion probabilities was computed. # words = 30203\n",
      "all branching entropies was computed # words = 45900\n",
      "all accessor variety was computed # words = 45900\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 36111\n",
      "_noun_scores_ 7753\n",
      "after postprocessing 5292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                            | 5/11 [11:10<13:43, 137.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 3.879 Gbory 3.761 Gb\n",
      "all cohesion probabilities was computed. # words = 31183\n",
      "all branching entropies was computed # words = 53001\n",
      "all accessor variety was computed # words = 53001\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 37523\n",
      "_noun_scores_ 7746\n",
      "after postprocessing 5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▋                                     | 6/11 [13:31<11:31, 138.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 6.424 Gbory 6.295 Gb\n",
      "all cohesion probabilities was computed. # words = 34169\n",
      "all branching entropies was computed # words = 56436\n",
      "all accessor variety was computed # words = 56436\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 40481\n",
      "_noun_scores_ 8564\n",
      "after postprocessing 5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▏                             | 7/11 [16:14<09:45, 146.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 7.434 Gbory 7.321 Gb\n",
      "all cohesion probabilities was computed. # words = 30136\n",
      "all branching entropies was computed # words = 44624\n",
      "all accessor variety was computed # words = 44624\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 35466\n",
      "_noun_scores_ 7698\n",
      "after postprocessing 5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▋                      | 8/11 [18:22<07:01, 140.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 3.905 Gbory 3.790 Gb\n",
      "all cohesion probabilities was computed. # words = 30197\n",
      "all branching entropies was computed # words = 44433\n",
      "all accessor variety was computed # words = 44433\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 35847\n",
      "_noun_scores_ 7805\n",
      "after postprocessing 5212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████               | 9/11 [20:31<04:33, 136.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 4.736 Gbory 4.624 Gb\n",
      "all cohesion probabilities was computed. # words = 29059\n",
      "all branching entropies was computed # words = 43303\n",
      "all accessor variety was computed # words = 43303\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 34850\n",
      "_noun_scores_ 7668\n",
      "after postprocessing 5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████████████████████████████████████████████████████████████████████▋       | 10/11 [22:28<02:10, 130.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 4.908 Gbory 4.819 Gb\n",
      "all cohesion probabilities was computed. # words = 22984\n",
      "all branching entropies was computed # words = 35475\n",
      "all accessor variety was computed # words = 35475\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 27928\n",
      "_noun_scores_ 6185\n",
      "after postprocessing 4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 11/11 [23:03<00:00, 125.75s/it]\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.233 Gbory 1.232 Gb\n",
      "all cohesion probabilities was computed. # words = 7047\n",
      "all branching entropies was computed # words = 12453\n",
      "all accessor variety was computed # words = 12453\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 9361\n",
      "_noun_scores_ 2037\n",
      "after postprocessing 1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▌                                                                           | 1/11 [00:05<00:53,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.714 Gbory 1.714 Gb\n",
      "all cohesion probabilities was computed. # words = 8223\n",
      "all branching entropies was computed # words = 13865\n",
      "all accessor variety was computed # words = 13865\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 10635\n",
      "_noun_scores_ 2365\n",
      "after postprocessing 1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████████████                                                                    | 2/11 [00:10<00:49,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.811 Gbory 1.811 Gb\n",
      "all cohesion probabilities was computed. # words = 9981\n",
      "all branching entropies was computed # words = 16840\n",
      "all accessor variety was computed # words = 16840\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 12245\n",
      "_noun_scores_ 2771\n",
      "after postprocessing 1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▋                                                            | 3/11 [00:17<00:48,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.981 Gbory 1.981 Gb\n",
      "all cohesion probabilities was computed. # words = 8399\n",
      "all branching entropies was computed # words = 12471\n",
      "all accessor variety was computed # words = 12471\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 10880\n",
      "_noun_scores_ 2466\n",
      "after postprocessing 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████████████████████▏                                                    | 4/11 [00:23<00:42,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.916 Gbory 1.916 Gb\n",
      "all cohesion probabilities was computed. # words = 9189\n",
      "all branching entropies was computed # words = 13083\n",
      "all accessor variety was computed # words = 13083\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 11766\n",
      "_noun_scores_ 2746\n",
      "after postprocessing 1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▋                                             | 5/11 [00:30<00:37,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.049 Gbory 2.049 Gb\n",
      "all cohesion probabilities was computed. # words = 10216\n",
      "all branching entropies was computed # words = 14558\n",
      "all accessor variety was computed # words = 14558\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 13085\n",
      "_noun_scores_ 3105\n",
      "after postprocessing 1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [00:38<00:34,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.226 Gbory 2.226 Gb\n",
      "all cohesion probabilities was computed. # words = 11567\n",
      "all branching entropies was computed # words = 16635\n",
      "all accessor variety was computed # words = 16635\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 14944\n",
      "_noun_scores_ 3521\n",
      "after postprocessing 2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [00:48<00:31,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.468 Gbory 2.468 Gb\n",
      "all cohesion probabilities was computed. # words = 11001\n",
      "all branching entropies was computed # words = 16061\n",
      "all accessor variety was computed # words = 16061\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 14059\n",
      "_noun_scores_ 3262\n",
      "after postprocessing 2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [00:56<00:24,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.365 Gbory 2.365 Gb\n",
      "all cohesion probabilities was computed. # words = 10331\n",
      "all branching entropies was computed # words = 14579\n",
      "all accessor variety was computed # words = 14579\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 13325\n",
      "_noun_scores_ 3256\n",
      "after postprocessing 2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [01:04<00:15,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.333 Gbory 2.333 Gb\n",
      "all cohesion probabilities was computed. # words = 9371\n",
      "all branching entropies was computed # words = 13364\n",
      "all accessor variety was computed # words = 13364\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 12332\n",
      "_noun_scores_ 3029\n",
      "after postprocessing 1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [01:11<00:07,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.248 Gbry 2.248 Gb\n",
      "all cohesion probabilities was computed. # words = 6387\n",
      "all branching entropies was computed # words = 9868\n",
      "all accessor variety was computed # words = 9868\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 8626\n",
      "_noun_scores_ 2150\n",
      "after postprocessing 1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [01:15<00:00,  6.86s/it]\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.631 Gbry 1.631 Gb\n",
      "all cohesion probabilities was computed. # words = 2917\n",
      "all branching entropies was computed # words = 8760\n",
      "all accessor variety was computed # words = 8760\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4218\n",
      "_noun_scores_ 926\n",
      "after postprocessing 548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▌                                                                           | 1/11 [00:01<00:16,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.783 Gbry 1.783 Gb\n",
      "all cohesion probabilities was computed. # words = 3187\n",
      "all branching entropies was computed # words = 9684\n",
      "all accessor variety was computed # words = 9684\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4670\n",
      "_noun_scores_ 1016\n",
      "after postprocessing 607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████████████                                                                    | 2/11 [00:03<00:15,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.821 Gbry 1.821 Gb\n",
      "all cohesion probabilities was computed. # words = 3956\n",
      "all branching entropies was computed # words = 12263\n",
      "all accessor variety was computed # words = 12263\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 5793\n",
      "_noun_scores_ 1257\n",
      "after postprocessing 769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▋                                                            | 3/11 [00:05<00:15,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.886 Gbry 1.886 Gb\n",
      "all cohesion probabilities was computed. # words = 3345\n",
      "all branching entropies was computed # words = 5359\n",
      "all accessor variety was computed # words = 5359\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4733\n",
      "_noun_scores_ 1072\n",
      "after postprocessing 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████████████████████▏                                                    | 4/11 [00:07<00:13,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.850 Gbry 1.850 Gb\n",
      "all cohesion probabilities was computed. # words = 3766\n",
      "all branching entropies was computed # words = 6103\n",
      "all accessor variety was computed # words = 6103\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 5198\n",
      "_noun_scores_ 1149\n",
      "after postprocessing 683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▋                                             | 5/11 [00:09<00:12,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.881 Gbry 1.881 Gb\n",
      "all cohesion probabilities was computed. # words = 3068\n",
      "all branching entropies was computed # words = 4939\n",
      "all accessor variety was computed # words = 4939\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4310\n",
      "_noun_scores_ 965\n",
      "after postprocessing 567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [00:11<00:09,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.847 Gbry 1.847 Gb\n",
      "all cohesion probabilities was computed. # words = 3350\n",
      "all branching entropies was computed # words = 5318\n",
      "all accessor variety was computed # words = 5318\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4585\n",
      "_noun_scores_ 1055\n",
      "after postprocessing 619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [00:13<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.885 Gbry 1.885 Gb\n",
      "all cohesion probabilities was computed. # words = 2933\n",
      "all branching entropies was computed # words = 4467\n",
      "all accessor variety was computed # words = 4467\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4117\n",
      "_noun_scores_ 964\n",
      "after postprocessing 569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [00:14<00:05,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.864 Gbry 1.864 Gb\n",
      "all cohesion probabilities was computed. # words = 3165\n",
      "all branching entropies was computed # words = 4584\n",
      "all accessor variety was computed # words = 4584\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4481\n",
      "_noun_scores_ 1089\n",
      "after postprocessing 645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [00:16<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.882 Gbry 1.882 Gb\n",
      "all cohesion probabilities was computed. # words = 2995\n",
      "all branching entropies was computed # words = 4863\n",
      "all accessor variety was computed # words = 4863\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 4385\n",
      "_noun_scores_ 1033\n",
      "after postprocessing 616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [00:18<00:01,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.883 Gbry 1.883 Gb\n",
      "all cohesion probabilities was computed. # words = 2018\n",
      "all branching entropies was computed # words = 3517\n",
      "all accessor variety was computed # words = 3517\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 3124\n",
      "_noun_scores_ 796\n",
      "after postprocessing 453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:19<00:00,  1.73s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 2.870 Gbse memory 2.913 Gb\n",
      "all cohesion probabilities was computed. # words = 106814\n",
      "all branching entropies was computed # words = 168311\n",
      "all accessor variety was computed # words = 168311\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 122347\n",
      "_noun_scores_ 24618\n",
      "after postprocessing 17435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [07:44<07:44, 464.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 3.780 Gbse memory 3.776 Gb\n",
      "all cohesion probabilities was computed. # words = 119329\n",
      "all branching entropies was computed # words = 172440\n",
      "all accessor variety was computed # words = 172440\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 135607\n",
      "_noun_scores_ 27967\n",
      "after postprocessing 19664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [17:05<00:00, 512.93s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.05it/s]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 3.675 Gbory 3.666 Gb\n",
      "all cohesion probabilities was computed. # words = 34750\n",
      "all branching entropies was computed # words = 49321\n",
      "all accessor variety was computed # words = 49321\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 41055\n",
      "_noun_scores_ 8983\n",
      "after postprocessing 6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [03:04<03:04, 184.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 4.835 Gbory 4.620 Gb\n",
      "all cohesion probabilities was computed. # words = 46259\n",
      "all branching entropies was computed # words = 58545\n",
      "all accessor variety was computed # words = 58545\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 53983\n",
      "_noun_scores_ 12359\n",
      "after postprocessing 8491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [08:24<00:00, 252.00s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.736 Gbory 0.672 Gb\n",
      "all cohesion probabilities was computed. # words = 16599\n",
      "all branching entropies was computed # words = 32282\n",
      "all accessor variety was computed # words = 32282\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 20981\n",
      "_noun_scores_ 4582\n",
      "after postprocessing 3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:19<00:19, 20.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 3.557 Gbory 3.553 Gb\n",
      "all cohesion probabilities was computed. # words = 17030\n",
      "all branching entropies was computed # words = 22021\n",
      "all accessor variety was computed # words = 22021\n",
      "C:/Users/KK/anaconda3/Lib/site-packages/soynlp\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "cannot access local variable 'f' where it is not associated with a value\n",
      "before postprocessing 20810\n",
      "_noun_scores_ 4728\n",
      "after postprocessing 3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:39<00:00, 19.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# # 연도데이터 기준 전처리\n",
    "# wf_soy, waf_soy, wf_tf, waf_tf = preprocessing_wordfreq(df_news, colname_target='제목', colname_category='일자', \n",
    "#                          save_local=True)\n",
    "# wfc_soy, wafc_soy, wfc_tf, wafc_tf = preprocessing_wordfreq(df_newsc, colname_target='제목', colname_category='일자', \n",
    "#                          save_local=True,\n",
    "#                          save_name_list=['word_freq_soynlp_c.csv', 'wordadj_freq_soynlp_c.csv', \n",
    "#                                          'word_freq_tfidf_c.csv', 'wordadj_freq_tfidf_c.csv'])\n",
    "# wfp_soy, wafp_soy, wfp_tf, wafp_tf = preprocessing_wordfreq(df_newsp, colname_target='제목', colname_category='일자', \n",
    "#                          save_local=True,\n",
    "#                          save_name_list=['word_freq_soynlp_p.csv', 'wordadj_freq_soynlp_p.csv', \n",
    "#                                          'word_freq_tfidf_p.csv', 'wordadj_freq_tfidf_p.csv'])\n",
    "\n",
    "# # 연도그룹데이터 기준 전처리\n",
    "# wf_era_soy, waf_era_soy, wf_era_tf, waf_era_tf = preprocessing_wordfreq(df_news_era, colname_target='제목', colname_category='일자', \n",
    "#                          save_local=True,\n",
    "#                          save_name_list=['word_freq_soynlp_era.csv', 'wordadj_freq_soynlp_era.csv', \n",
    "#                                          'word_freq_tfidf_era.csv', 'wordadj_freq_tfidf_era.csv'])\n",
    "# ## 안되면 아래줄 실행\n",
    "# wf_era_tf = wf_tf.copy()\n",
    "# wf_era_tf.category.apply(lambda x: '2013 ~ 2017' if x in ['2013', '2014', '2015', '2016', '2017']\n",
    "#                                                   else '2018 ~ 2023')\n",
    "# wf_era_tf = wf_era_tf.groupby(list(wf_era_tf.columns[:2])).mean().reset_index()\n",
    "# waf_era_tf = pd.DataFrame()\n",
    "# for category in tqdm(sorted(df_news_era[COLNAME_CATEGORY].unique())):\n",
    "#     df_sub = df_news_era[df_news_era[COLNAME_CATEGORY] == category]\n",
    "#     waf_era = preprocessing_adjwordcount(wf_era_tf[['word']], df_sub[COLNAME_MINING], num_showkeyword=5)\n",
    "#     waf_era['category'] = str(category)\n",
    "#     waf_era = waf_era[['category']+list(waf_era.columns[:-1])]\n",
    "#     waf_era_tf = pd.concat([waf_era_tf, waf_era], axis=0, ignore_index=True)\n",
    "# save_name = os.path.join(os.getcwd(), 'Data', 'word_freq_tfidf_era.csv')\n",
    "# wf_era_tf.to_csv(save_name, index=False, encoding='utf-8-sig')\n",
    "# save_name = os.path.join(os.getcwd(), 'Data', 'wordadj_freq_tfidf_era.csv')\n",
    "# waf_era_tf.to_csv(save_name, index=False, encoding='utf-8-sig')\n",
    "# ######################\n",
    "# wfc_era_soy, wafc_era_soy, wfc_era_tf, wafc_era_tf = preprocessing_wordfreq(df_newsc_era, colname_target='제목', colname_category='일자', \n",
    "#                          save_local=True,\n",
    "#                          save_name_list=['word_freq_soynlp_erac.csv', 'wordadj_freq_soynlp_erac.csv', \n",
    "#                                          'word_freq_tfidf_erac.csv', 'wordadj_freq_tfidf_erac.csv'])\n",
    "# wfp_era_soy, wafp_era_soy, wfp_era_tf, wafp_era_tf = preprocessing_wordfreq(df_newsp_era, colname_target='제목', colname_category='일자', \n",
    "#                          save_local=True,\n",
    "#                          save_name_list=['word_freq_soynlp_erap.csv', 'wordadj_freq_soynlp_erap.csv', \n",
    "#                                          'word_freq_tfidf_erap.csv', 'wordadj_freq_tfidf_erap.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f682cbf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T01:32:01.573035Z",
     "start_time": "2023-10-14T01:32:00.129008Z"
    }
   },
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "save_name_list=['word_freq_soynlp.csv', 'wordadj_freq_soynlp.csv', \n",
    "                'word_freq_tfidf.csv', 'wordadj_freq_tfidf.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wf_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "waf_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wf_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "waf_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "save_name_list=['word_freq_soynlp_c.csv', 'wordadj_freq_soynlp_c.csv', \n",
    "                'word_freq_tfidf_c.csv', 'wordadj_freq_tfidf_c.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wfc_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "wafc_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wfc_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "wafc_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "save_name_list=['word_freq_soynlp_p.csv', 'wordadj_freq_soynlp_p.csv', \n",
    "                'word_freq_tfidf_p.csv', 'wordadj_freq_tfidf_p.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wfp_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "wafp_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wfp_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "wafp_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "# 불러오기\n",
    "save_name_list=['word_freq_soynlp_era.csv', 'wordadj_freq_soynlp_era.csv', \n",
    "                'word_freq_tfidf_era.csv', 'wordadj_freq_tfidf_era.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wf_era_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "waf_era_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wf_era_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "waf_era_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "save_name_list=['word_freq_soynlp_erac.csv', 'wordadj_freq_soynlp_erac.csv', \n",
    "                'word_freq_tfidf_erac.csv', 'wordadj_freq_tfidf_erac.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wfc_era_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "wafc_era_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wfc_era_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "wafc_era_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "save_name_list=['word_freq_soynlp_erap.csv', 'wordadj_freq_soynlp_erap.csv', \n",
    "                'word_freq_tfidf_erap.csv', 'wordadj_freq_tfidf_erap.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wfp_era_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "wafp_era_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wfp_era_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "wafp_era_tfidf = pd.read_csv(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5d3ec",
   "metadata": {},
   "source": [
    "## Word Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5972ab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T02:00:27.687929Z",
     "start_time": "2023-10-14T01:32:01.574033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:24<00:00, 12.34s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.73s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05<00:00,  2.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.72s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.87s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [23:17<00:00, 698.65s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.35s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:13<00:00, 126.58s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# # 관련성 전처리\n",
    "# wf_corr_soynlp = preprocessing_wordfreq_to_corr(wf_era_soynlp, df_news_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='word_corrpair_soynlp_era.csv')\n",
    "# waf_corr_soynlp = preprocessing_wordfreq_to_corr(waf_era_soynlp, df_news_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='wordadj_corrpair_soynlp_era.csv')\n",
    "# wf_corr_tfidf = preprocessing_wordfreq_to_corr(wf_era_tfidf, df_news_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='word_corrpair_tfidf_era.csv')\n",
    "# waf_corr_tfidf = preprocessing_wordfreq_to_corr(waf_era_tfidf, df_news_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='wordadj_corrpair_tfidf_era.csv')\n",
    "\n",
    "# wfc_corr_soynlp = preprocessing_wordfreq_to_corr(wfc_era_soynlp, df_newsc_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='word_corrpair_soynlp_era_c.csv')\n",
    "# wafc_corr_soynlp = preprocessing_wordfreq_to_corr(wafc_era_soynlp, df_newsc_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='wordadj_corrpair_soynlp_era_c.csv')\n",
    "# wfc_corr_tfidf = preprocessing_wordfreq_to_corr(wfc_era_tfidf, df_newsc_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='word_corrpair_tfidf_era_c.csv')\n",
    "# wafc_corr_tfidf = preprocessing_wordfreq_to_corr(wafc_era_tfidf, df_newsc_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='wordadj_corrpair_tfidf_era_c.csv')\n",
    "\n",
    "# wfp_corr_soynlp = preprocessing_wordfreq_to_corr(wfp_era_soynlp, df_newsp_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='word_corrpair_soynlp_era_p.csv')\n",
    "# wafp_corr_soynlp = preprocessing_wordfreq_to_corr(wafp_era_soynlp, df_newsp_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='wordadj_corrpair_soynlp_era_p.csv')\n",
    "# wfp_corr_tfidf = preprocessing_wordfreq_to_corr(wfp_era_tfidf, df_newsp_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='word_corrpair_tfidf_era_p.csv')\n",
    "# wafp_corr_tfidf = preprocessing_wordfreq_to_corr(wafp_era_tfidf, df_newsp_era, colname_target=COLNAME_MINING, colname_category=COLNAME_CATEGORY, num_showkeyword=100, save_name='wordadj_corrpair_tfidf_era_p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d660ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-14T02:00:28.087458Z",
     "start_time": "2023-10-14T02:00:27.691997Z"
    }
   },
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "save_name_list=['word_corrpair_soynlp_era.csv', 'wordadj_corrpair_soynlp_era.csv', \n",
    "                'word_corrpair_tfidf_era.csv', 'wordadj_corrpair_tfidf_era.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wf_corr_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "waf_corr_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wf_corr_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "waf_corr_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "save_name_list=['word_corrpair_soynlp_era_c.csv', 'wordadj_corrpair_soynlp_era_c.csv', \n",
    "                'word_corrpair_tfidf_era_c.csv', 'wordadj_corrpair_tfidf_era_c.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wfc_corr_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "wafc_corr_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wfc_corr_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "wafc_corr_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "save_name_list=['word_corrpair_soynlp_era_p.csv', 'wordadj_corrpair_soynlp_era_p.csv', \n",
    "                'word_corrpair_tfidf_era_p.csv', 'wordadj_corrpair_tfidf_era_p.csv']\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[0])\n",
    "wfp_corr_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[1])\n",
    "wafp_corr_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[2])\n",
    "wfp_corr_tfidf = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', save_name_list[3])\n",
    "wafp_corr_tfidf = pd.read_csv(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e555054",
   "metadata": {},
   "source": [
    "# 연구문제0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a248e0",
   "metadata": {},
   "source": [
    "## Ageism Global Trend and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0769485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.871452Z",
     "start_time": "2023-10-13T14:36:37.871452Z"
    }
   },
   "outputs": [],
   "source": [
    "for each in [df_gt_global, df_gt_local]:\n",
    "    model, Score_te = modeling_LGBMRegressor_slidingwindow1D(each, SEQUENCE=SEQUENCE, Y_SCALING=Y_SCALING, MOVING_TYPE=MOVING_TYPE,\n",
    "                                                   TRAIN_WINDOW=TRAIN_WINDOW, FORECASTING_PERIOD=FORECASTING_PERIOD,\n",
    "                                                   LOSS=LOSS_ML, GRIDSEARCH_PARAMS=PARAMS_BOOST, CV_SPLITS=CV_SPLITS,\n",
    "                                                   PLOT_TITLE=PLOT_TITLE, PLOT_XLABEL=PLOT_XLABEL, PLOT_YLABEL=PLOT_YLABEL)\n",
    "    display(Score_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28167b93",
   "metadata": {},
   "source": [
    "## Korea Trend by Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a8de0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.871452Z",
     "start_time": "2023-10-13T14:36:37.871452Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 증가변수 필터\n",
    "RISING_CATEG = ['고령화', '노인+경제적+자립', '노인+봉사', '노인+의료', \n",
    "                '노인+주택+문제', '노인+혐오', '돌봄서비스', '세대+갈등', '소회', \n",
    "                '안락사', '알츠하이머', '연령+통합']\n",
    "df_news_rising = df_news_rising[RISING_CATEG].copy()\n",
    "## 시각화\n",
    "plot_timeseries_dforigin(df_news_rising, save_local=True, save_name_initial='gt_total_origin.png')\n",
    "plot_timeseries_dfmeanstd(df_news_rising, scaled=True, save_local=True, save_name_initial='gt_total_scaled.png')\n",
    "plot_timeseries(df_news_rising, save_local=True, save_name_initial='gt_each_origin.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda85dce",
   "metadata": {},
   "source": [
    "# 연구문제1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426b804",
   "metadata": {},
   "source": [
    "## 과거 10년 동안의 온라인 검색어 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a43138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.872449Z",
     "start_time": "2023-10-13T14:36:37.872449Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word freq 비교 트랜드 시각화\n",
    "plot_treemap_wordfreq(wf_soynlp, num_showkeyword=100, title='Ageism by Year', plot_studio=True, save_local=True, save_name='trend_year_compare_treemap.html')\n",
    "plot_sunburst_wordfreq(waf_soynlp, title='Ageism by Year', plot_studio=True, save_local=True, save_name='trend_year_compare_sunburst.html')\n",
    "plot_bar_wordfreq(wf_soynlp, figsize=(30,8), num_showkeyword=20, title='Ageism by Year', save_local=True, save_name='trend_year_compare_bar_byword.png')\n",
    "plot_bar_wordfreq(waf_soynlp, figsize=(30,8), num_showkeyword=20, title='Ageism by Year', save_local=True, save_name='trend_year_compare_bar_bywordadj.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0719708",
   "metadata": {},
   "source": [
    "## 고령사회 전후의 온라인 검색어 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fe1a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.873446Z",
     "start_time": "2023-10-13T14:36:37.873446Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 연도별 word freq 시각화\n",
    "centrality_categ = pd.DataFrame()\n",
    "for category in wf_era_soynlp[wf_era_soynlp.columns[0]].unique():\n",
    "    print(category)\n",
    "    wf_sub = wf_era_soynlp.groupby(wf_era_soynlp.columns[0]).get_group(category)\n",
    "    wc_sub = wf_corr_soynlp[wf_corr_soynlp.category.isin([category])]\n",
    "    \n",
    "    plot_wordcloud(wf_sub.iloc[:,1:], mask_colorgen=False, max_words=100, mask_location=IMAGE_LOCATION, save_local=True, save_name='trend_era_wordcloud_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    plot_bar_wordfreq(wf_sub.iloc[:,1:], figsize=(16,8), num_showkeyword=100, title='Ageism by Era', \n",
    "                      save_local=True, save_name='trend_era_bar_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    plot_donut_wordfreq(wf_sub.iloc[:,1:], num_showkeyword=30, save_local=True, save_name='trend_era_donut_'+'~'.join(category.split(' ~ '))+'.html')\n",
    "    _, centrality = plot_networkx(wf_sub, wc_sub.iloc[:,1:], \n",
    "                                  filter_criteria=0.02, plot=True, node_size='pagerank', save_local=True, save_name='trend_era_networkx_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    ## 카테고리 추가\n",
    "    centrality['category'] = str(category)\n",
    "    centrality_categ = pd.concat([centrality_categ, centrality], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a57352d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.873446Z",
     "start_time": "2023-10-13T14:36:37.873446Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word freq 비교 트랜드 시각화\n",
    "plot_treemap_wordfreq(wf_era_soynlp, num_showkeyword=100, title='Ageism_Era', plot_studio=True, save_name='trend_era_compare_treemap_'+'~'.join(category.split(' ~ '))+'.html')\n",
    "plot_sunburst_wordfreq(waf_era_soynlp, title='Ageism_Era', plot_studio=True, save_name='trend_era_compare_sunburst_'+'~'.join(category.split(' ~ '))+'.html')\n",
    "plot_bar_wordfreq(wf_era_soynlp, figsize=(20,8), num_showkeyword=20, title='Ageism_Era', save_local=True, save_name='trend_era_compare_bar_byword_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "plot_bar_wordfreq(waf_era_soynlp, figsize=(20,8), num_showkeyword=20, title='Ageism_Era', save_local=True, save_name='trend_era_compare_bar_bywordadj_'+'~'.join(category.split(' ~ '))+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b352bf",
   "metadata": {},
   "source": [
    "## 과거 10년 동안의 보수 및 진보 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173a997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.874442Z",
     "start_time": "2023-10-13T14:36:37.874442Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word freq 비교 트랜드 시각화\n",
    "plot_treemap_wordfreq(wfc_soynlp, num_showkeyword=100, title='Ageism by Year+Conservative', plot_studio=True, save_local=True, save_name='trend_yearc_compare_treemap.html')\n",
    "plot_treemap_wordfreq(wfp_soynlp, num_showkeyword=100, title='Ageism by Year+Progressive', plot_studio=True, save_local=True, save_name='trend_yearp_compare_treemap.html')\n",
    "plot_sunburst_wordfreq(wafc_soynlp, title='Ageism by Year+Conservative', plot_studio=True, save_local=True, save_name='trend_yearc_compare_sunburst.html')\n",
    "plot_sunburst_wordfreq(wafp_soynlp, title='Ageism by Year+Progressive', plot_studio=True, save_local=True, save_name='trend_yearp_compare_sunburst.html')\n",
    "plot_bar_wordfreq(wfc_soynlp, figsize=(30,8), num_showkeyword=20, title='Ageism by Year+Conservative', save_local=True, save_name='trend_yearc_compare_bar_byword.png')\n",
    "plot_bar_wordfreq(wfp_soynlp, figsize=(30,8), num_showkeyword=20, title='Ageism by Year+Progressive', save_local=True, save_name='trend_yearp_compare_bar_byword.png')\n",
    "plot_bar_wordfreq(wafc_soynlp, figsize=(30,8), num_showkeyword=20, title='Ageism by Year+Conservative', save_local=True, save_name='trend_yearc_compare_bar_bywordadj.png')\n",
    "plot_bar_wordfreq(wafp_soynlp, figsize=(30,8), num_showkeyword=20, title='Ageism by Year+Progressive', save_local=True, save_name='trend_yearp_compare_bar_bywordadj.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd4194",
   "metadata": {},
   "source": [
    "## 고령사회 전후의 보수 및 진보 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887dd28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.875440Z",
     "start_time": "2023-10-13T14:36:37.875440Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 연도별 word freq 시각화\n",
    "centrality_categ = pd.DataFrame()\n",
    "for category in wfc_era_soynlp[wfc_era_soynlp.columns[0]].unique():\n",
    "    print(category)\n",
    "    wf_subc = wfc_era_soynlp.groupby(wfc_era_soynlp.columns[0]).get_group(category)\n",
    "    wc_subc = wfc_corr_soynlp[wfc_corr_soynlp.category.isin([category])]\n",
    "    wf_subp = wfp_era_soynlp.groupby(wfp_era_soynlp.columns[0]).get_group(category)\n",
    "    wc_subp = wfp_corr_soynlp[wfp_corr_soynlp.category.isin([category])]\n",
    "    \n",
    "    plot_wordcloud(wf_subc.iloc[:,1:], mask_colorgen=False, max_words=100, mask_location=IMAGE_LOCATION, save_local=True, save_name='trend_erac_wordcloud_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    plot_wordcloud(wf_subp.iloc[:,1:], mask_colorgen=False, max_words=100, mask_location=IMAGE_LOCATION, save_local=True, save_name='trend_erap_wordcloud_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    plot_bar_wordfreq(wf_subc.iloc[:,1:], num_showkeyword=100, save_local=True, save_name='trend_erac_bar_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    plot_bar_wordfreq(wf_subp.iloc[:,1:], num_showkeyword=100, save_local=True, save_name='trend_erap_bar_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    plot_donut_wordfreq(wf_subc.iloc[:,1:], num_showkeyword=30, save_local=True, save_name='trend_erac_donut_'+'~'.join(category.split(' ~ '))+'.html')\n",
    "    plot_donut_wordfreq(wf_subp.iloc[:,1:], num_showkeyword=30, save_local=True, save_name='trend_erap_donut_'+'~'.join(category.split(' ~ '))+'.html')\n",
    "    _, centrality = plot_networkx(wf_subc, wc_subc.iloc[:,1:], \n",
    "                                  filter_criteria=0.025, plot=True, node_size='pagerank', save_local=True, save_name='trend_erac_networkx_'+'~'.join(category.split(' ~ '))+'.png')\n",
    "    _, centrality = plot_networkx(wf_subp, wc_subp.iloc[:,1:], \n",
    "                                  filter_criteria=0.025, plot=True, node_size='pagerank', save_local=True, save_name='trend_erap_networkx_'+'~'.join(category.split(' ~ '))+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8042b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.875440Z",
     "start_time": "2023-10-13T14:36:37.875440Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word freq 비교 트랜드 시각화\n",
    "plot_treemap_wordfreq(wfc_era_soynlp, num_showkeyword=100, title='Ageism_Era_Conservative', plot_studio=True, save_local=True, save_name='trend_erac_compare_treemap.html')\n",
    "plot_treemap_wordfreq(wfp_era_soynlp, num_showkeyword=100, title='Ageism_Era_Progressive', plot_studio=True, save_local=True, save_name='trend_erap_compare_treemap.html')\n",
    "plot_sunburst_wordfreq(wafc_era_soynlp, title='Ageism_Era_Conservative', plot_studio=True, save_name='trend_erac_compare_sunburst.html')\n",
    "plot_sunburst_wordfreq(wafp_era_soynlp, title='Ageism_Era_Progressive', plot_studio=True, save_name='trend_erap_compare_sunburst.html')\n",
    "plot_bar_wordfreq(wfc_era_soynlp, figsize=(20,8), num_showkeyword=20, title='Ageism_Era_Conservative', save_local=True, save_name='trend_erac_compare_bar_byword.png')\n",
    "plot_bar_wordfreq(wfp_era_soynlp, figsize=(20,8), num_showkeyword=20, title='Ageism_Era_Progressive', save_local=True, save_name='trend_erap_compare_bar_byword.png')\n",
    "plot_bar_wordfreq(wafc_era_soynlp, figsize=(20,8), num_showkeyword=20, title='Ageism_Era_Conservative', save_local=True, save_name='trend_erac_compare_bar_bywordadj.png')\n",
    "plot_bar_wordfreq(wafp_era_soynlp, figsize=(20,8), num_showkeyword=20, title='Ageism_Era_Progressive', save_local=True, save_name='trend_erap_compare_bar_bywordadj.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f05219",
   "metadata": {},
   "source": [
    "## 과거 10년 동안의 온라인 검색어 긍부정 데이터량 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f0abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcac9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20095bca",
   "metadata": {},
   "source": [
    "## 고령사회 전후의 온라인 검색어 긍부정 데이터량 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5936f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea3629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40c8f538",
   "metadata": {},
   "source": [
    "## 고령사회 전후의 보수 및 진보 긍부정 데이터량 트랜드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2d39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25496acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5edbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fe06b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb5f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05f00af2",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ab2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://teddylee777.github.io/huggingface/bert-kor-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518b202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.876436Z",
     "start_time": "2023-10-13T14:36:37.876436Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers\n",
    "# pip install --user onnxruntime\n",
    "# pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6c4a219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T15:42:38.393743Z",
     "start_time": "2023-10-13T15:42:35.492552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.5051401853561401},\n",
       " {'label': 'LABEL_1', 'score': 0.5508290529251099},\n",
       " {'label': 'LABEL_0', 'score': 0.5068181157112122},\n",
       " {'label': 'LABEL_0', 'score': 0.5064376592636108},\n",
       " {'label': 'LABEL_1', 'score': 0.5009700655937195},\n",
       " {'label': 'LABEL_1', 'score': 0.5229330062866211},\n",
       " {'label': 'LABEL_1', 'score': 0.5389445424079895},\n",
       " {'label': 'LABEL_0', 'score': 0.5130621790885925},\n",
       " {'label': 'LABEL_0', 'score': 0.5087025761604309},\n",
       " {'label': 'LABEL_0', 'score': 0.5162251591682434},\n",
       " {'label': 'LABEL_1', 'score': 0.5671678185462952},\n",
       " {'label': 'LABEL_1', 'score': 0.5056815147399902},\n",
       " {'label': 'LABEL_1', 'score': 0.5134280323982239},\n",
       " {'label': 'LABEL_1', 'score': 0.5134280323982239},\n",
       " {'label': 'LABEL_1', 'score': 0.5107713341712952},\n",
       " {'label': 'LABEL_0', 'score': 0.5095388293266296},\n",
       " {'label': 'LABEL_0', 'score': 0.5036386251449585},\n",
       " {'label': 'LABEL_1', 'score': 0.5339201092720032},\n",
       " {'label': 'LABEL_0', 'score': 0.5042920708656311},\n",
       " {'label': 'LABEL_1', 'score': 0.5162655711174011},\n",
       " {'label': 'LABEL_1', 'score': 0.5276274681091309},\n",
       " {'label': 'LABEL_1', 'score': 0.5477614998817444},\n",
       " {'label': 'LABEL_0', 'score': 0.5036386251449585},\n",
       " {'label': 'LABEL_0', 'score': 0.5330550074577332},\n",
       " {'label': 'LABEL_1', 'score': 0.5099400281906128},\n",
       " {'label': 'LABEL_1', 'score': 0.551214873790741},\n",
       " {'label': 'LABEL_1', 'score': 0.5438188314437866},\n",
       " {'label': 'LABEL_1', 'score': 0.551214873790741},\n",
       " {'label': 'LABEL_1', 'score': 0.5447263121604919},\n",
       " {'label': 'LABEL_1', 'score': 0.5293839573860168},\n",
       " {'label': 'LABEL_1', 'score': 0.5360885262489319},\n",
       " {'label': 'LABEL_1', 'score': 0.5325960516929626},\n",
       " {'label': 'LABEL_1', 'score': 0.5360885262489319},\n",
       " {'label': 'LABEL_1', 'score': 0.5360885262489319},\n",
       " {'label': 'LABEL_1', 'score': 0.5360885262489319},\n",
       " {'label': 'LABEL_1', 'score': 0.5164640545845032},\n",
       " {'label': 'LABEL_0', 'score': 0.5121491551399231},\n",
       " {'label': 'LABEL_0', 'score': 0.5107515454292297},\n",
       " {'label': 'LABEL_1', 'score': 0.5684475302696228},\n",
       " {'label': 'LABEL_1', 'score': 0.5587658286094666},\n",
       " {'label': 'LABEL_0', 'score': 0.5259248614311218},\n",
       " {'label': 'LABEL_1', 'score': 0.5305361747741699},\n",
       " {'label': 'LABEL_0', 'score': 0.5028945207595825},\n",
       " {'label': 'LABEL_0', 'score': 0.5309380888938904},\n",
       " {'label': 'LABEL_1', 'score': 0.5684475302696228},\n",
       " {'label': 'LABEL_0', 'score': 0.5238134264945984},\n",
       " {'label': 'LABEL_1', 'score': 0.5045271515846252},\n",
       " {'label': 'LABEL_1', 'score': 0.5826674699783325},\n",
       " {'label': 'LABEL_1', 'score': 0.5243670344352722},\n",
       " {'label': 'LABEL_1', 'score': 0.5764475464820862},\n",
       " {'label': 'LABEL_1', 'score': 0.5504702925682068},\n",
       " {'label': 'LABEL_0', 'score': 0.5076915621757507},\n",
       " {'label': 'LABEL_1', 'score': 0.569290041923523},\n",
       " {'label': 'LABEL_1', 'score': 0.5371423959732056},\n",
       " {'label': 'LABEL_0', 'score': 0.5424516797065735},\n",
       " {'label': 'LABEL_1', 'score': 0.5048113465309143},\n",
       " {'label': 'LABEL_1', 'score': 0.5045271515846252},\n",
       " {'label': 'LABEL_1', 'score': 0.5556527972221375},\n",
       " {'label': 'LABEL_0', 'score': 0.5221575498580933},\n",
       " {'label': 'LABEL_1', 'score': 0.5579318404197693},\n",
       " {'label': 'LABEL_1', 'score': 0.543035626411438},\n",
       " {'label': 'LABEL_1', 'score': 0.5498051643371582},\n",
       " {'label': 'LABEL_1', 'score': 0.5371015667915344},\n",
       " {'label': 'LABEL_0', 'score': 0.5234946012496948},\n",
       " {'label': 'LABEL_1', 'score': 0.5298250913619995},\n",
       " {'label': 'LABEL_1', 'score': 0.5263807773590088},\n",
       " {'label': 'LABEL_0', 'score': 0.5013083219528198},\n",
       " {'label': 'LABEL_1', 'score': 0.5239657163619995},\n",
       " {'label': 'LABEL_0', 'score': 0.5400283336639404},\n",
       " {'label': 'LABEL_1', 'score': 0.5325186252593994},\n",
       " {'label': 'LABEL_1', 'score': 0.5025384426116943},\n",
       " {'label': 'LABEL_1', 'score': 0.5169856548309326},\n",
       " {'label': 'LABEL_1', 'score': 0.501420259475708},\n",
       " {'label': 'LABEL_0', 'score': 0.5352144837379456},\n",
       " {'label': 'LABEL_1', 'score': 0.511924684047699},\n",
       " {'label': 'LABEL_0', 'score': 0.5154950618743896},\n",
       " {'label': 'LABEL_0', 'score': 0.5768795609474182},\n",
       " {'label': 'LABEL_1', 'score': 0.5780414938926697},\n",
       " {'label': 'LABEL_1', 'score': 0.5184774994850159},\n",
       " {'label': 'LABEL_1', 'score': 0.5019620060920715},\n",
       " {'label': 'LABEL_1', 'score': 0.5373266935348511},\n",
       " {'label': 'LABEL_1', 'score': 0.5905725955963135},\n",
       " {'label': 'LABEL_1', 'score': 0.5062865018844604},\n",
       " {'label': 'LABEL_1', 'score': 0.5483605861663818},\n",
       " {'label': 'LABEL_1', 'score': 0.5295881628990173},\n",
       " {'label': 'LABEL_1', 'score': 0.5197708010673523},\n",
       " {'label': 'LABEL_1', 'score': 0.5376894474029541},\n",
       " {'label': 'LABEL_1', 'score': 0.5183656811714172},\n",
       " {'label': 'LABEL_1', 'score': 0.5649526715278625},\n",
       " {'label': 'LABEL_1', 'score': 0.5431073904037476},\n",
       " {'label': 'LABEL_0', 'score': 0.5609819889068604},\n",
       " {'label': 'LABEL_1', 'score': 0.5446143746376038},\n",
       " {'label': 'LABEL_1', 'score': 0.5219016671180725},\n",
       " {'label': 'LABEL_1', 'score': 0.5095143914222717},\n",
       " {'label': 'LABEL_1', 'score': 0.519599974155426},\n",
       " {'label': 'LABEL_1', 'score': 0.5037177205085754},\n",
       " {'label': 'LABEL_1', 'score': 0.5354712605476379},\n",
       " {'label': 'LABEL_1', 'score': 0.5281474590301514},\n",
       " {'label': 'LABEL_1', 'score': 0.5174607038497925},\n",
       " {'label': 'LABEL_1', 'score': 0.5363938212394714}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, BertTokenizer, BertTokenizerFast\n",
    "from transformers import AutoModel, AutoModelForTokenClassification, TFBertModel, TFBertForSequenceClassification\n",
    "\n",
    "TASK = 'text-classification'\n",
    "MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "model_sa = pipeline(task=TASK, model=MODEL_NAME)\n",
    "result = model_sa(df_news['제목'].to_list()[:100])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09da4617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T16:24:00.685908Z",
     "start_time": "2023-10-13T16:24:00.253389Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 9121.22it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_sentence_to_BERTinput(df_series, tokenizer, seq_len=128):\n",
    "    tokens, masks, segments = [], [], []\n",
    "    for i in tqdm(range(len(df_series))):\n",
    "        # token : 문장을 토큰화함\n",
    "        token = tokenizer.encode(df_series[i], max_length=seq_len, padding='max_length', truncation=True)\n",
    "        \n",
    "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
    "        num_zeros = token.count(0)\n",
    "        mask = [1]*(seq_len-num_zeros) + [0]*num_zeros\n",
    "        \n",
    "        # 문장의 전후관계를 구분해주는 세그먼트\n",
    "        segment = [0]*seq_len\n",
    "        \n",
    "        # 정리\n",
    "        tokens.append(token)\n",
    "        masks.append(mask)\n",
    "        segments.append(segment)\n",
    "        \n",
    "    # array 변환\n",
    "    tokens = np.array(tokens)\n",
    "    masks = np.array(masks)\n",
    "    segments = np.array(segments)\n",
    "    \n",
    "    return [tokens, masks, segments]\n",
    "\n",
    "MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "X_train = preprocessing_sentence_to_BERTinput(df_news['제목'][:100], tokenizer=tokenizer)\n",
    "\n",
    "def modeling_BERTsentiment(model_name, optimizer, seq_len=128):\n",
    "    # 입력 변환\n",
    "    tokens = tf.keras.layers.Input((seq_len,), dtype=tf.int32, name='input_ids')\n",
    "    masks = tf.keras.layers.Input((seq_len,), dtype=tf.int32, name='input_masks')\n",
    "    segments = tf.keras.layers.Input((seq_len,), dtype=tf.int32, name='input_segments')\n",
    "    \n",
    "    # 모델 로딩\n",
    "    model = TFBertModel.from_pretrained(model_name)\n",
    "    outputs = model([tokens, masks, segments])[1]\n",
    "    \n",
    "    # 모델 구성\n",
    "    layer = tf.keras.layers.Dense(1, activation='sigmoid', \n",
    "                                  kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(outputs)\n",
    "    model_sentiment = tf.keras.Model([tokens, masks, segments], layer)\n",
    "    model_sentiment.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
    "    \n",
    "    return model_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35756a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df544a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421a001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.878430Z",
     "start_time": "2023-10-13T14:36:37.878430Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "save_name = os.path.join(os.getcwd(), 'Data', 'word_freq_soynlp.csv')\n",
    "word_freq_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', 'wordadj_freq_soynlp.csv')\n",
    "wordadj_freq_soynlp = pd.read_csv(save_name)\n",
    "save_name = os.path.join(os.getcwd(), 'Data', 'word_score_tfidf.csv')\n",
    "word_score_tfidf = pd.read_csv(save_name)\n",
    "\n",
    "FREQ_USING = word_freq_soynlp.copy()    # word_freq_soynlp, wordadj_freq_soynlp, word_score_tfidf\n",
    "\n",
    "dict_word_corr, df_word_corrpair = dict(), pd.DataFrame()\n",
    "centrality_years = pd.DataFrame()\n",
    "for year in tqdm(sorted(df[COLNAME_CATEGORY].dt.year.unique())):\n",
    "    print(year)\n",
    "    \n",
    "    # 데이터 분리\n",
    "    df_sub = df[df[COLNAME_CATEGORY].dt.year == year]\n",
    "    df_subfreq = FREQ_USING[FREQ_USING[FREQ_USING.columns[0]] == year]\n",
    "    \n",
    "    # 단어 벡터화 및 상관관계\n",
    "    _, word_corr, word_corrpair = preprocessing_wordfreq_to_vectorcorr(df_subfreq.iloc[:,-2:], \n",
    "                                                                       df_sub[COLNAME_MINING])\n",
    "    dict_word_corr[year] = word_corr\n",
    "#     ## 카테고리 추가\n",
    "#     word_corrpair['year'] = str(year)\n",
    "#     word_corrpair = word_corrpair[['year']+list(word_corrpair.columns[:-1])]\n",
    "#     df_word_corrpair = pd.concat([df_word_corrpair, word_corrpair], axis=0, ignore_index=True)\n",
    "    \n",
    "#     # 시각화\n",
    "#     _, centrality = plot_networkx(df_subfreq, word_corrpair.iloc[:,1:], filter_criteria=None, \n",
    "#                                   plot=True, node_size='pagerank')\n",
    "#     ## 카테고리 추가\n",
    "#     centrality['year'] = str(year)\n",
    "#     centrality_years = pd.concat([centrality_years, centrality], axis=0, ignore_index=True)\n",
    "# G, centrality_total = plot_networkx(FREQ_USING, df_word_corrpair.iloc[:,1:], filter_criteria=None, \n",
    "#                                     plot=True, node_size='pagerank')\n",
    "    \n",
    "# 저장\n",
    "# save_name = os.path.join(os.getcwd(), 'Data', 'word_freq_soynlp.csv')\n",
    "# word_freq_soynlp.to_csv(save_name, index=False, encoding='utf-8-sig')\n",
    "# save_name = os.path.join(os.getcwd(), 'Data', 'wordadj_freq_soynlp.csv')\n",
    "# wordadj_freq_soynlp.to_csv(save_name, index=False, encoding='utf-8-sig')\n",
    "# save_name = os.path.join(os.getcwd(), 'Data', 'word_score_tfidf.csv')\n",
    "# word_score_tfidf.to_csv(save_name, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f61b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.879425Z",
     "start_time": "2023-10-13T14:36:37.879425Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_colnames = list(word_corr.columns[word_corr.sum()>=0.5])\n",
    "word_corr.loc[sub_colnames,:].loc[:,sub_colnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150e7fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.880423Z",
     "start_time": "2023-10-13T14:36:37.880423Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "mat_square = nx.from_numpy_array(word_corr.loc[sub_colnames,:].loc[:,sub_colnames].values)\n",
    "vis = Network(notebook=False, cdn_resources='local', height='1000px', width='1000px')\n",
    "vis.from_nx(mat_square)\n",
    "vis.show_buttons(filter_=True)\n",
    "vis.save_graph('nx.html')\n",
    "# vis.show('test1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0135c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.881419Z",
     "start_time": "2023-10-13T14:36:37.881419Z"
    }
   },
   "outputs": [],
   "source": [
    "nx.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d0028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af62dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396041f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff344e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.881419Z",
     "start_time": "2023-10-13T14:36:37.881419Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/chord-diagrams-of-protein-interaction-networks-in-python-9589affc8b91\n",
    "    \n",
    "import nxviz as nv\n",
    "from nxviz import annotate, highlights\n",
    "from nxviz.plots import despine, rescale, respine\n",
    "\n",
    "def plot_nxviz(df_freq, df_pairweight, filter_criteria=None):\n",
    "    pass\n",
    "\n",
    "G, centrality_total = plot_networkx(FREQ_USING, df_word_corrpair, filter_criteria=None, plot=False)\n",
    "ax = nv.circos(G, group_by=\"group_node\", node_color_by=\"group_node\")\n",
    "annotate.circos_labels(G, group_by=\"group_node\", radius=np.pi)\n",
    "annotate.node_colormapping(G, color_by='group_node')\n",
    "# annotate.node_labels(G, group_by=\"group_node\", sort_by='score')\n",
    "annotate.circos_group(G, group_by=\"group_node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611b4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713aa0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.882415Z",
     "start_time": "2023-10-13T14:36:37.882415Z"
    }
   },
   "outputs": [],
   "source": [
    "# 과거 5년 이후 5년 시각화 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f4bad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.883412Z",
     "start_time": "2023-10-13T14:36:37.883412Z"
    }
   },
   "outputs": [],
   "source": [
    "nx.from_pandas_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ea390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525eb620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60edbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798115f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90df1d4c",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ee915",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T14:36:37.884411Z",
     "start_time": "2023-10-13T14:36:37.884411Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 데이터로딩\n",
    "# df_news = get_data_from_path(FOLDER_LOCATION)\n",
    "# df = df_news.copy()\n",
    "# ## 날짜 인식\n",
    "# df = df[df.Date != 'None'].reset_index().iloc[:,1:]\n",
    "# df.Date = pd.to_datetime(df.Date)\n",
    "# ## 중복 처리\n",
    "# df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "# ## 전처리\n",
    "# df.Category = df.Category.apply(lambda x: text_preprocessor(x, del_bracket_content=False))\n",
    "# df.Title = df.Title.apply(lambda x: text_preprocessor(x, del_bracket_content=True))\n",
    "# df.Content = df.Content.apply(lambda x: text_preprocessor(x, del_bracket_content=False))\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259d82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8131b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497942ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce8135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37657a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
